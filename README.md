<p align="center">
  <a href="" rel="noopener">
 <img width=200px height=200px src="https://www.svgrepo.com/show/353657/django-icon.svg" alt="Project logo"></a>
</p>

<h3 align="center">Beem√¥n challenge</h3>

<div align="center">

[![Status](https://img.shields.io/badge/status-active-success.svg)]()
[![GitHub Issues](https://img.shields.io/github/issues/kylelobo/The-Documentation-Compendium.svg)](https://github.com/Tutuacs/beemontech-challenge/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/kylelobo/The-Documentation-Compendium.svg)](https://github.com/Tutuacs/beemontech-challenge/pulls)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)

</div>

---

<p align="center"> Este projeto foi feito para comprovar experi√™ncia e conhecimentos para a vaga com foco em webscraping com python, Django. O desafio escolhido foi com o site <a href= "https://quotes.toscrape.com/">quotes</a>.
    <br> 
</p>

## üìù Conte√∫dos

- [Sobre](#about)
- [Iniciando](#getting_started)
- [Deploy](#deployment)
- [Uso](#usage)
- [Feito com](#built_using)
- [Desenvolvido por](#authors)
- [Finaliza√ß√£o](#acknowledgement)

## üßê Sobre <a name = "about"></a>

Este projeto √© um desafio de webscrapping, onde o objetivo √© extrair informa√ß√µes de uma p√°gina web e armazen√°-las em um banco de dados. O projeto utiliza Django como framework web e Sqlite ou PostgreSQL como banco de dados.

## üèÅ Iniciando <a name = "getting_started"></a>

Estas instru√ß√µes permitir√£o que voc√™ obtenha uma c√≥pia do projeto em execu√ß√£o na sua m√°quina local para fins de desenvolvimento e teste. Veja a se√ß√£o de [deploy](#deployment) para saber como rodar o projeto.

### Pr√©-requisitos

Para rodar o projeto corretamente, voc√™ precisar√° ter instalado em sua m√°quina:

```
Docker
```

### Instala√ß√£o

Passo a passo, realize os seguintes passos para rodar o projeto:

Install docker

```
https://docs.docker.com/engine/install/
```

Clone the repository

```sh
git clone https://github.com/Tutuacs/beemontech-challenge.git
```

Using VsCode?

```sh
code beemontech-challenge
```

## üöÄ Deploy <a name = "deployment"></a>

Para fazer o deploy do projeto, voc√™ pode usar o Docker para criar um container com Redis, PostgreSQL, API e Service.

```sh
sudo docker compose up -d --build
```

Acessar a aplica√ß√£o no navegador:

```
http://localhost:8000/swagger
```

A api principal funciona sem Redis, mas n√£o ter√° a funcionalidade de agendamento de updates. Para que funcione corretamente, √© necess√°rio rodar o servi√ßo subscribe, que ir√° escutar as mensagens do Redis e executar as tarefas de scraping no per√≠odo programado, nesta branch o docker est√° configurado para rodar automaticamente ambos, servidor e servi√ßo.

## üìå Uso <a name = "usage"></a>

Principais rotas:
- [/live](http://localhost:8000/swagger) - Mostra os dados atuais do site
- [/update](http://localhost:8000/swagger) - Atualiza os dados do banco de dados com os dados mais recentes do site, apenas criando novos dados n√£o existentes.
- [/pandas/csv](http://localhost:8000/swagger) - Gera um DataFrame CSV com os dados atuais do banco de dados, utilizando a biblioteca Pandas.
- [/pandas/json](http://localhost:8000/swagger) - Gera um DataFrame JSON com os dados atuais do banco de dados, utilizando a biblioteca Pandas.
- [{POST} /schedule](http://localhost:8000/swagger) - Agenda uma tarefa de scraping para ser executada em um per√≠odo espec√≠fico, utilizando o Redis como broker de mensagens.

## ‚õèÔ∏è Feito com <a name = "built_using"></a>

- [PostgreSQL](https://www.postgresql.org/) - Database
- [Django](https://www.djangoproject.com/) - Server Framework
- [BeautifulSoup](https://pypi.org/project/beautifulsoup4/) - Scraping Library
- [Redis](https://redis.io/) - Message Broker
- [Docker](https://www.docker.com/) - Containerization Platform

## ‚úçÔ∏è Desenvolvido por <a name = "authors"></a>

- [@ArthurSilva](https://github.com/Tutuacs) - Dev

See also the list of [contributors](https://github.com/Tutuacs/beemontech-challenge/contributors) who participated in this project.

## üéâ Finaliza√ß√£o <a name = "acknowledgement"></a>

- IMPORTATE: Ao criar uma *"schedule"*, a data enviada n√£o √© verificada, criando com uma data menor que a data atual resultar√° uma schedule com status FAIL.

##### Melhorias Importantes:
  - Rota */live* deveria ser feita com Ws para que o usu√°rio possa acompanhar as atualiza√ß√µes em tempo real, para isso, seria necess√°rio alterar a fun√ß√£o que faz o scraping para receber uma conex√£o WebSocket e enviar os dados atualizados para a conex√£o recebida conforme o scraping √© feito.
  - Rota */update* deveria ser feita usando Redis Pub/Sub, publicando os objetos encontrados no scraping para que outro servi√ßo possa cuidar da parte de salvar os dados no banco de dados, assim, o servi√ßo de scraping n√£o ficaria bloqueado e a resposta da rota */update* seria mais r√°pida.

##### References

  - [Django Video](https://youtu.be/XAzVlnPDVd0?si=HPWwvPxa0ugR4AMz)
  - [Python && Redis](https://dev.to/felipepaz/python-e-redis-utilizando-pubsub-51fo)
  - [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
  - [Pandas](https://www.w3schools.com/Python/pandas/pandas_dataframes.asp)
